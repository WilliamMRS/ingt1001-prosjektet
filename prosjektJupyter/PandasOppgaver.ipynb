{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Element2_Pandas import* #importerer python-filen som en modul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 1:\n",
    "Har importert filen 2342202.csv i python-filen og kalt den for \"df_opg1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser at dataen er organisert i 92099 rader og fire kolonner: Station, Name, Date og TAVG.\n",
    "Datasettet består av datatypene \"object\" og \"float64\" hvor TAVG består av \"float64\"-verdier og resten er \"object\".\n",
    "\n",
    "NB! Vi legger merke til at i TAVG kolonnen så finnes det bare 7606 rader som ikke er null-verdier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US1NYWC0003</td>\n",
       "      <td>WHITE PLAINS 3.1 NNW, NY US</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US1NYWC0003</td>\n",
       "      <td>WHITE PLAINS 3.1 NNW, NY US</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US1NYWC0003</td>\n",
       "      <td>WHITE PLAINS 3.1 NNW, NY US</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US1NYWC0003</td>\n",
       "      <td>WHITE PLAINS 3.1 NNW, NY US</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US1NYWC0003</td>\n",
       "      <td>WHITE PLAINS 3.1 NNW, NY US</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                         NAME        DATE  TAVG\n",
       "0  US1NYWC0003  WHITE PLAINS 3.1 NNW, NY US  2017-01-03   NaN\n",
       "1  US1NYWC0003  WHITE PLAINS 3.1 NNW, NY US  2017-01-04   NaN\n",
       "2  US1NYWC0003  WHITE PLAINS 3.1 NNW, NY US  2017-01-05   NaN\n",
       "3  US1NYWC0003  WHITE PLAINS 3.1 NNW, NY US  2017-01-06   NaN\n",
       "4  US1NYWC0003  WHITE PLAINS 3.1 NNW, NY US  2017-01-09   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92099 entries, 0 to 92098\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   STATION  92099 non-null  object \n",
      " 1   NAME     92099 non-null  object \n",
      " 2   DATE     92099 non-null  object \n",
      " 3   TAVG     7606 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_opg1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oppgave 3:\n",
    "Dropper duplikerte rader og rader med null-verdier vha. \"drop_dup_nan\" funksjonen, og fikser index-verdiene vha. \"fix_index\" funksjonen.\n",
    "\n",
    "Vi ser at det nå er kun 7606 gjenværende rader i df_opg1. Dette er fordi at en stor majoritet av de 92099 radene i TAVG-kolonnen inneholdt null-verdier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7606 entries, 0 to 7605\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   STATION  7606 non-null   object \n",
      " 1   NAME     7606 non-null   object \n",
      " 2   DATE     7606 non-null   object \n",
      " 3   TAVG     7606 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 237.8+ KB\n"
     ]
    }
   ],
   "source": [
    "drop_dup_nan(df_opg1)\n",
    "fix_index(df_opg1)\n",
    "df_opg1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 4:\n",
    "Vi deler \"NAME\" kolonnen i to kolonner \"Area\" og \"Country\" vha. funksjonen \"split_NAME\" fra spyder-filen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>46.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>NY US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>34.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>NY US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION        DATE  TAVG               AREA COUNTRY\n",
       "0  USW00014732  2017-01-01  46.0  LAGUARDIA AIRPORT   NY US\n",
       "1  USW00014732  2017-01-02  40.0  LAGUARDIA AIRPORT   NY US\n",
       "2  USW00014732  2017-01-03  42.0  LAGUARDIA AIRPORT   NY US\n",
       "3  USW00014732  2017-01-04  47.0  LAGUARDIA AIRPORT   NY US\n",
       "4  USW00014732  2017-01-05  34.0  LAGUARDIA AIRPORT   NY US"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_NAME(df_opg1)\n",
    "df_opg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 5:\n",
    "Vi deler COUNTRY-kolonnen i to kolonner CITY og COUNTRY vha. \"split_COUNTRY\" funksjonen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>46.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>34.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION        DATE  TAVG               AREA COUNTRY CITY\n",
       "0  USW00014732  2017-01-01  46.0  LAGUARDIA AIRPORT      US   NY\n",
       "1  USW00014732  2017-01-02  40.0  LAGUARDIA AIRPORT      US   NY\n",
       "2  USW00014732  2017-01-03  42.0  LAGUARDIA AIRPORT      US   NY\n",
       "3  USW00014732  2017-01-04  47.0  LAGUARDIA AIRPORT      US   NY\n",
       "4  USW00014732  2017-01-05  34.0  LAGUARDIA AIRPORT      US   NY"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_COUNTRY(df_opg1)\n",
    "df_opg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 6: \n",
    "Vi har laget en funksjon \"fix_COUNTRY\" for å endre \"COUNTRY\"-kolonnen til landskoder på to bokstaver. I df_opg1 trengs ikke denne fordi vi allerede har gjort \"COUNTRY\"-kolonnen til landskoder på to bokstaver i oppgave 5.\n",
    "\n",
    "\"fix_COUNTRY\"-funksjonen gjør jobben effektivt ved å ta i bruk den innebygde pandas-funksjonen \"rsplit\" (\"Series.str.rsplit\"), men det finnes også alternative måter å løse denne oppgaven på. Under er to alternativer som ikke tar i bruk noen innebygde pandas-funksjoner:\n",
    "\n",
    "alternativ 1 - Funksjonen oppnår det samme resultatet som \"fix_COUNTRY\" funksjonen ved å gå gjennom hver rad i datasettet. Den splitter radens \"COUNTRY\"-verdi (som består av enten en landskode, eller en bykode og en landskode) til en liste, for så å sette radens \"COUNTRY\"-verdi lik det siste elementet i denne listen (som alltid vil være en landskode).\n",
    "\n",
    "```python\n",
    "def alternativ1(df):\n",
    "    for n in range(0, len(df)):\n",
    "        df[\"COUNTRY\"][n] = df[\"COUNTRY\"][n].split(\" \")[-1]```\n",
    "\n",
    "alternativ 2 - Funksjonen har den samme funksjonaliteten som alternativ 1, men tar i bruk en while-løkke i stedet for en for-løkke.\n",
    "```python\n",
    "def alternativ2(df):\n",
    "    n = 0\n",
    "    while n < len(df):\n",
    "        df[\"COUNTRY\"][n] = df[\"COUNTRY\"][n].split(\" \")[-1]      \n",
    "        n+=1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 7:\n",
    "I spyder-filen har vi importert filen \"2342207.csv\", og kalt den for \"df_opg7\". Vi har også definert en funksjon \"trinn_3_4_6\" for å gjøre trinn 3, 4 og 6 for en valgfri df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIE00142101</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>33.0</td>\n",
       "      <td>HELSINKI ILMALA</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIE00142101</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>26.0</td>\n",
       "      <td>HELSINKI ILMALA</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIE00142101</td>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>21.0</td>\n",
       "      <td>HELSINKI ILMALA</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIE00142101</td>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>9.0</td>\n",
       "      <td>HELSINKI ILMALA</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIE00142101</td>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HELSINKI ILMALA</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION      DATE  TAVG             AREA COUNTRY\n",
       "0  FIE00142101  1/1/2017  33.0  HELSINKI ILMALA      FI\n",
       "1  FIE00142101  1/2/2017  26.0  HELSINKI ILMALA      FI\n",
       "2  FIE00142101  1/3/2017  21.0  HELSINKI ILMALA      FI\n",
       "3  FIE00142101  1/4/2017   9.0  HELSINKI ILMALA      FI\n",
       "4  FIE00142101  1/5/2017   1.0  HELSINKI ILMALA      FI"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trinn_3_4_6(df_opg7)\n",
    "df_opg7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 8:\n",
    "Bruker funksjonen \"combine_dfs\" fra spyder-filen for å sette sammen df_opg1 og df_opg7 til en df_opg8, og for å fikse index-verdiene til den resulterende df-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opg8 = combine_dfs(df_opg1, df_opg7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>46.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>40.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>47.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00014732</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>34.0</td>\n",
       "      <td>LAGUARDIA AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION        DATE  TAVG               AREA COUNTRY CITY\n",
       "0  USW00014732  2017-01-01  46.0  LAGUARDIA AIRPORT      US   NY\n",
       "1  USW00014732  2017-01-02  40.0  LAGUARDIA AIRPORT      US   NY\n",
       "2  USW00014732  2017-01-03  42.0  LAGUARDIA AIRPORT      US   NY\n",
       "3  USW00014732  2017-01-04  47.0  LAGUARDIA AIRPORT      US   NY\n",
       "4  USW00014732  2017-01-05  34.0  LAGUARDIA AIRPORT      US   NY"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opg8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 9:\n",
    "For å kontrollere at df-en fra trinn 8 er riktig kan vi sjekke at lengden på df-en fra trinn 8 er lik summen av lengdene til de to tidligere df-ene som den består av. Dersom lengdene samsvarer kan vi konkludere med at alle radene fra de to tidligere df-ene også finnes i den nye df-en fra trinn 8, og at den dermed sannsynligvis er slik som vi forventer.\n",
    "\n",
    "Dette har vi laget en funksjon for i Spyder-filen kalt \"kontroll\". \n",
    "\n",
    "Funksjonen printer \"Riktig lengde\" dersom lengden til de to tidligere df-ene samsvarer med lengden på df_opg8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riktig lengde\n"
     ]
    }
   ],
   "source": [
    "kontroll(df_opg1, df_opg7, df_opg8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 11:\n",
    "I spyder-filen har vi importert alle filene fra \"weather\"-mappen og lagret dem i en liste kalt \"all_dfs\".\n",
    "\n",
    "Vi har også definert en funksjon \"fix_dfs_in_list\" som kjører trinn 3, 4 og 6 for hver df i en liste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_dfs_in_list(all_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 12:\n",
    "I spyder-filen har vi importert \"Trondheim.csv\"-filen og kalt den \"df_trondheim\".\n",
    "Vi kjører trinn 3, 4 og 6 for \"df_trondheim\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trinn_3_4_6(df_trondheim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Oppgave 13:\n",
    "Lager en ny kolonne TAVG som er gjennomsnittet av TMIN og TMAX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trondheim[\"TAVG\"] = (df_trondheim[\"TMIN\"]+df_trondheim[\"TMAX\"])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 14:\n",
    "Endrer df_trondheim slik at rekkefølgen er lik rekkefølgen til de andre df-ene, og slik at \"TMIN\" og \"TMAX\" ikke blir med. \n",
    "\n",
    "Dette gjøres vha. funksjonen \"df_make_default\" som vi har definert i spyder-filen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trondheim = df_make_default(df_trondheim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOE00111040</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>TRONDHEIM VOLL</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOE00111040</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>30.5</td>\n",
       "      <td>TRONDHEIM VOLL</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOE00111040</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>30.5</td>\n",
       "      <td>TRONDHEIM VOLL</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOE00111040</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>20.5</td>\n",
       "      <td>TRONDHEIM VOLL</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOE00111040</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>TRONDHEIM VOLL</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION        DATE  TAVG            AREA COUNTRY\n",
       "0  NOE00111040  2017-01-01  34.0  TRONDHEIM VOLL      NO\n",
       "1  NOE00111040  2017-01-02  30.5  TRONDHEIM VOLL      NO\n",
       "2  NOE00111040  2017-01-03  30.5  TRONDHEIM VOLL      NO\n",
       "3  NOE00111040  2017-01-04  20.5  TRONDHEIM VOLL      NO\n",
       "4  NOE00111040  2017-01-05  14.0  TRONDHEIM VOLL      NO"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trondheim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 15:\n",
    "Skal kombinere alle df-ene til en større df kalt \"df_complete\".\n",
    "Vi har definert en funksjon \"combine_dfs_in_list\" som kombinerer alle df-er i en liste vha. pandas \"concat-funksjonen\". For å gjøre dette må vi først legge \"df_trondheim\" til i listen \"all_dfs\" sammen med alle de andre df-ene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = combine_dfs_in_list(all_dfs, df_trondheim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>26.0</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>34.0</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>37.0</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>31.0</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION      DATE  TAVG        AREA COUNTRY\n",
       "0  DEW00035032  1/1/2017  26.0  RHIEN MAIN      DE\n",
       "1  DEW00035032  1/2/2017  32.0  RHIEN MAIN      DE\n",
       "2  DEW00035032  1/3/2017  34.0  RHIEN MAIN      DE\n",
       "3  DEW00035032  1/4/2017  37.0  RHIEN MAIN      DE\n",
       "4  DEW00035032  1/5/2017  31.0  RHIEN MAIN      DE"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 16:\n",
    "importerer \"countryContinent.csv\" til en df kalt \"df_country_continent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_continent = pd.read_csv('Datasets/countryContinent.csv', encoding=\"iso_8859_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 17:\n",
    "Vi kan se at df_country_continent er strukturert i 9 kolonner. \n",
    "\n",
    "Kolonnene inneholder informasjon om land, som hvilke region de befinner seg i, regions-koden, lands-koden osv. \n",
    "\n",
    "Blant all denne informasjonen er det mye som kan være unyttig når vi analyserer temperaturdata. Det som kan være nyttig å vite derimot er: land, lands-kode, kontinent og region. Fordi denne informasjonen er relevant til temperaturdataen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>code_2</th>\n",
       "      <th>code_3</th>\n",
       "      <th>country_code</th>\n",
       "      <th>iso_3166_2</th>\n",
       "      <th>continent</th>\n",
       "      <th>sub_region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>sub_region_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>ISO 3166-2:AF</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "      <td>ALA</td>\n",
       "      <td>248</td>\n",
       "      <td>ISO 3166-2:AX</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8</td>\n",
       "      <td>ISO 3166-2:AL</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>12</td>\n",
       "      <td>ISO 3166-2:DZ</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>ISO 3166-2:AS</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>ISO 3166-2:AD</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "      <td>24</td>\n",
       "      <td>ISO 3166-2:AO</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Middle Africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>AI</td>\n",
       "      <td>AIA</td>\n",
       "      <td>660</td>\n",
       "      <td>ISO 3166-2:AI</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Antarctica</td>\n",
       "      <td>AQ</td>\n",
       "      <td>ATA</td>\n",
       "      <td>10</td>\n",
       "      <td>ISO 3166-2:AQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>AG</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>ISO 3166-2:AG</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               country code_2 code_3  country_code     iso_3166_2 continent  \\\n",
       "0          Afghanistan     AF    AFG             4  ISO 3166-2:AF      Asia   \n",
       "1        Åland Islands     AX    ALA           248  ISO 3166-2:AX    Europe   \n",
       "2              Albania     AL    ALB             8  ISO 3166-2:AL    Europe   \n",
       "3              Algeria     DZ    DZA            12  ISO 3166-2:DZ    Africa   \n",
       "4       American Samoa     AS    ASM            16  ISO 3166-2:AS   Oceania   \n",
       "5              Andorra     AD    AND            20  ISO 3166-2:AD    Europe   \n",
       "6               Angola     AO    AGO            24  ISO 3166-2:AO    Africa   \n",
       "7             Anguilla     AI    AIA           660  ISO 3166-2:AI  Americas   \n",
       "8           Antarctica     AQ    ATA            10  ISO 3166-2:AQ       NaN   \n",
       "9  Antigua and Barbuda     AG    ATG            28  ISO 3166-2:AG  Americas   \n",
       "\n",
       "        sub_region  region_code  sub_region_code  \n",
       "0    Southern Asia        142.0             34.0  \n",
       "1  Northern Europe        150.0            154.0  \n",
       "2  Southern Europe        150.0             39.0  \n",
       "3  Northern Africa          2.0             15.0  \n",
       "4        Polynesia          9.0             61.0  \n",
       "5  Southern Europe        150.0             39.0  \n",
       "6    Middle Africa          2.0             17.0  \n",
       "7        Caribbean         19.0             29.0  \n",
       "8              NaN          NaN              NaN  \n",
       "9        Caribbean         19.0             29.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_continent.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 18:\n",
    "Bruker \"merge\" funksjonen til å slå sammen \"df_complete\" og \"df_country_continent\" til en df \"df_complete_cont\".\n",
    "\n",
    "Vi slår de sammen med hensyn på kolonnene \"COUNTRY\" (fra \"df_complete\") og \"code_2\" (fra \"df_country_continent\"), fordi disse kolonnene samsvarer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_cont = pd.merge(df_complete, df_country_continent, left_on=\"COUNTRY\", right_on=\"code_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 19:\n",
    "Har definert en funksjon \"trinn19()\" i spyder-filen som dropper kolonnen \"code_2\", og gir nye navn til de forespurte kolonnene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_cont = trinn19(df_complete_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 21:\n",
    "Vi har definert en funksjon i spyder-filen \"column_values()\" som finner, sorterer og returnerer alle unike verdier fra en kolonne i en dataframe. \n",
    "\n",
    "Her har vi tatt i bruk de innebygde pandas funksjonene \"sort_values()\" og \"unique()\" for å kun ta med unike navn på land og for å sortere listen alfabetisk.\n",
    "\n",
    "Alternativt kunne man enkelt ha definert en funksjon for dette på egenhånd også på måten vist under. Her definerer vi først en tom liste \"unique_values\", og går så gjennom hvert land i kolonnen \"Country\" i \"df_complete_cont\". Dersom landet ikke allerede finnes i listen \"unique_values\" så legger vi det til i listen. Deretter bruker vi den innebygde python-funksjonen \"sorted()\" til å sortere listen alfabetisk:\n",
    "\n",
    "\n",
    "```python\n",
    "def alternativ(df, column):\n",
    "    unique_values = []\n",
    "\n",
    "    for value in list(df[column]):\n",
    "        if value not in unique_values:       \n",
    "            unique_values.append(value)\n",
    "    unique_values = sorted(unique_values)\n",
    "    \n",
    "alternativ(df_complete_cont, \"Country\")```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_in_df = column_values(df_complete_cont, \"Country\")\n",
    "continents_in_df = column_values(df_complete_cont, \"Continent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 22:\n",
    "Vi har definert en funksjon \"f_to_c()\" i spyder som konverterer grader i fahrenheit til grader i celcius. Vi bruker den til å konvertere alle verdiene i kolonnen \"TAVG\" til celcius.\n",
    "\n",
    "Konverteringen fra fahrenheit til celcius gikk uten problemer, i stor grad fordi vi kunne ta i bruk en enkel funksjon for å konvertere alle verdiene samtidig. Dersom det derimot hadde fantes en blanding av verdier målt i celcius og fahrenheit uten at enhetene var oppgitt, hadde vi hatt et mye vanskeligere problem å løse. \n",
    "\n",
    "Dersom vi skulle konvertert denne blandingen av temperaturenheter til én enhet måtte vi først og fremst sjekket om verdiene var målt i Celcius eller i Fahrenheit. Det finnes ikke en måte å gjøre dette på med 100% sikkerhet, men vi kunne prøvd å rasjonalisere oss fram til et svar. Vi vet at alle temperaturer over 56.7 grader må være målt i fahrenheit, med mindre de har satt en ny varmerekord. Om man anntar at hvert land bruker én temperatur-enhet så kan vi konkludere med at alle målingene fra land som har temperatur-verdier over 56.7 grader bruker enheten fahrenheit. Deretter gjenstår landene som kun har målinger under 56.7 grader. For å finne ut hvilken enhet disse målingene er gjort i så kan vi sammenligne med målinger fra omkringliggende land som vi allerede har bestemt at har temperatur målt i fahrenheit. For eksempel ved å se på andre land som ligger i samme region, sub-region og på samme kontinent. Om landets temperatur ligger langt under omkringliggende lands gjennomsnittstemperatur så kan vi konkludere med at målingene er gjort i celcius. Deretter kunne vi konvertert kun de målingene som var i \"feil\" enhet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_cont[\"TAVG\"] = f_to_c(df_complete_cont[\"TAVG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AREA</th>\n",
       "      <th>Country-code</th>\n",
       "      <th>Country</th>\n",
       "      <th>code_3</th>\n",
       "      <th>country_code</th>\n",
       "      <th>iso_3166_2</th>\n",
       "      <th>Continent</th>\n",
       "      <th>sub_region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>sub_region_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>276</td>\n",
       "      <td>ISO 3166-2:DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>0.00</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>276</td>\n",
       "      <td>ISO 3166-2:DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>1.11</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>276</td>\n",
       "      <td>ISO 3166-2:DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>2.78</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>276</td>\n",
       "      <td>ISO 3166-2:DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEW00035032</td>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>RHIEN MAIN</td>\n",
       "      <td>DE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>276</td>\n",
       "      <td>ISO 3166-2:DE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>150.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40345</th>\n",
       "      <td>KZ000035188</td>\n",
       "      <td>12/27/2019</td>\n",
       "      <td>-12.22</td>\n",
       "      <td>ASTANA</td>\n",
       "      <td>KZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>398</td>\n",
       "      <td>ISO 3166-2:KZ</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40346</th>\n",
       "      <td>KZ000035188</td>\n",
       "      <td>12/28/2019</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>ASTANA</td>\n",
       "      <td>KZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>398</td>\n",
       "      <td>ISO 3166-2:KZ</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40347</th>\n",
       "      <td>KZ000035188</td>\n",
       "      <td>12/29/2019</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>ASTANA</td>\n",
       "      <td>KZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>398</td>\n",
       "      <td>ISO 3166-2:KZ</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40348</th>\n",
       "      <td>KZ000035188</td>\n",
       "      <td>12/30/2019</td>\n",
       "      <td>-13.33</td>\n",
       "      <td>ASTANA</td>\n",
       "      <td>KZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>398</td>\n",
       "      <td>ISO 3166-2:KZ</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40349</th>\n",
       "      <td>KZ000035188</td>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>-14.44</td>\n",
       "      <td>ASTANA</td>\n",
       "      <td>KZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>398</td>\n",
       "      <td>ISO 3166-2:KZ</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40350 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           STATION        DATE   TAVG        AREA Country-code     Country  \\\n",
       "0      DEW00035032    1/1/2017  -3.33  RHIEN MAIN           DE     Germany   \n",
       "1      DEW00035032    1/2/2017   0.00  RHIEN MAIN           DE     Germany   \n",
       "2      DEW00035032    1/3/2017   1.11  RHIEN MAIN           DE     Germany   \n",
       "3      DEW00035032    1/4/2017   2.78  RHIEN MAIN           DE     Germany   \n",
       "4      DEW00035032    1/5/2017  -0.56  RHIEN MAIN           DE     Germany   \n",
       "...            ...         ...    ...         ...          ...         ...   \n",
       "40345  KZ000035188  12/27/2019 -12.22      ASTANA           KZ  Kazakhstan   \n",
       "40346  KZ000035188  12/28/2019  -5.00      ASTANA           KZ  Kazakhstan   \n",
       "40347  KZ000035188  12/29/2019  -5.00      ASTANA           KZ  Kazakhstan   \n",
       "40348  KZ000035188  12/30/2019 -13.33      ASTANA           KZ  Kazakhstan   \n",
       "40349  KZ000035188  12/31/2019 -14.44      ASTANA           KZ  Kazakhstan   \n",
       "\n",
       "      code_3  country_code     iso_3166_2 Continent      sub_region  \\\n",
       "0        DEU           276  ISO 3166-2:DE    Europe  Western Europe   \n",
       "1        DEU           276  ISO 3166-2:DE    Europe  Western Europe   \n",
       "2        DEU           276  ISO 3166-2:DE    Europe  Western Europe   \n",
       "3        DEU           276  ISO 3166-2:DE    Europe  Western Europe   \n",
       "4        DEU           276  ISO 3166-2:DE    Europe  Western Europe   \n",
       "...      ...           ...            ...       ...             ...   \n",
       "40345    KAZ           398  ISO 3166-2:KZ      Asia    Central Asia   \n",
       "40346    KAZ           398  ISO 3166-2:KZ      Asia    Central Asia   \n",
       "40347    KAZ           398  ISO 3166-2:KZ      Asia    Central Asia   \n",
       "40348    KAZ           398  ISO 3166-2:KZ      Asia    Central Asia   \n",
       "40349    KAZ           398  ISO 3166-2:KZ      Asia    Central Asia   \n",
       "\n",
       "       region_code  sub_region_code  \n",
       "0            150.0            155.0  \n",
       "1            150.0            155.0  \n",
       "2            150.0            155.0  \n",
       "3            150.0            155.0  \n",
       "4            150.0            155.0  \n",
       "...            ...              ...  \n",
       "40345        142.0            143.0  \n",
       "40346        142.0            143.0  \n",
       "40347        142.0            143.0  \n",
       "40348        142.0            143.0  \n",
       "40349        142.0            143.0  \n",
       "\n",
       "[40350 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemer og utfordringer vi møtte på underveis\n",
    "Da vi gikk gjennom disse oppgavene møtte vi på en rekke problemer og utfordringer underveis. Jeg mistenker at majoriteten av utfordringene vi møtte på kom fra for lite erfaring med verktøyene vi tok i bruk, som pandas, jupyter notebook og spyder.\n",
    "Til tross for at vi har jobbet med disse verktøyene tidligere så lærte vi mye underveis, og vi har fortsatt mye å lære for å kunne bruke disse verktøyene til deres fulle potensial.\n",
    "\n",
    "Da vi startet å jobbe så gikk vi gjennom alle oppgavene i kronologisk rekkefølge, og løste dem fortløpende i Spyder. Dette ga et godt overblikk over oppgavene og førte til at vi fant rimelige måter å løse dem på. Til tross for at det var en tidseffektiv måte å løse oppgavene i Spyder, så møtte vi på problemer da vi skulle presentere oppgavene i Jupyter. Koden var mye mer rotete enn den kunne ha vært, og vi hadde ikke tatt i bruk funksjoner i stor nok grad. Dette gjorde det umulig å presentere arbeidet i Jupyter uten å omskrive store deler av koden. I ettertid ser vi at vi kunne ha fått et bedre produkt raskere dersom vi hadde hatt en annen arbeidsmetode fra begynnelsen. For eksempel så var det flere oppgaver som måtte løses flere ganger, som oppgave 3, 4 og 6. Dersom vi hadde tatt tiden til å få et skikkelig overblikk over alle oppgavene før vi startet så kunne vi ha skrevet generelle funksjoner for å løse disse oppgavene fra begynnelsen, i stedet for å gå tilbake og løse disse oppgavene igjen da vi skulle presentere arbeidet i Jupyter.\n",
    "\n",
    "\n",
    "En annen del av oppgaven som vi fant spesielt utfordrende var oppgavene hvor vi skulle finne alternative måter å løse det samme problemet på. Å løse oppgavene vi ble bedt om gikk veldig fint, men da man allerede har funnet en måte å løse dem på så blir det ofte vanskelig å finne alternative måter. Muligens fordi man får litt tunnelsyn og \"låser seg inn\" på metoden som først ble brukt, og har vanskelig for å gå helt tilbake til begynnelsen. Dette var mer en utfordring enn et problem, og jeg ser ikke en bedre \"metode\" å løse disse oppgavene på. \n",
    "\n",
    "Utenom dette så møtte vi på mindre problemer som at vi hadde vanskeligheter med å importere python-koden som en modul til Jupyter. Vi fant det også utfordrende å drøfte hvordan vi kunne konvertert en blanding av temperaturer målt i Celcius og Fahrenheit til Fahrenheit. Men etter en del googling og tenking så løste dette seg også fint.\n",
    "\n",
    "Problemene vi møtte på kom nok først og fremst fra at vi fortsatt er i begynnerstadiet når det gjelder både koding, rapportskriving og problemløsning. Med mer erfaring vil vi kunne løse og unngå slike utfordringer lettere enn vi kan den dag i dag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
